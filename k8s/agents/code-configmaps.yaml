apiVersion: v1
kind: ConfigMap
metadata:
  name: manager-code
  namespace: agency
data:
  manager.py: |
    from kubernetes import client, config
    from supabase import create_client, Client
    import os
    import logging
    from typing import List, Dict, Any, Optional
    from mcp.server.fastmcp import FastMCP

    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("AgencyManager")

    class AgencyManager:
        def __init__(self):
            # 1. Initialize Supabase Connection
            self.supabase_url = os.getenv("SUPABASE_URL")
            self.supabase_key = os.getenv("SUPABASE_KEY")

            if not self.supabase_url or not self.supabase_key:
                logger.warning("Supabase credentials not found. Using mock mode for DB.")
                self.supabase = None
            else:
                self.supabase: Client = create_client(self.supabase_url, self.supabase_key)

            # 2. Initialize Kubernetes Connection
            try:
                # Tries to load in-cluster config first (production), then kubeconfig (local dev)
                try:
                    config.load_incluster_config()
                    logger.info("Loaded in-cluster Kubernetes config.")
                except config.ConfigException:
                    config.load_kube_config()
                    logger.info("Loaded local kubeconfig.")

                self.v1 = client.CoreV1Api()
                self.apps_v1 = client.AppsV1Api()
            except Exception as e:
                logger.error(f"Failed to connect to Kubernetes: {e}")
                self.v1 = None
                self.apps_v1 = None

        def list_active_agents(self) -> List[Dict[str, Any]]:
            """List all pods in the 'agency' namespace."""
            if not self.v1:
                return [{"error": "Kubernetes not connected"}]

            try:
                pods = self.v1.list_namespaced_pod(namespace="agency", label_selector="role=worker")
                agents = []
                for pod in pods.items:
                    agents.append({
                        "name": pod.metadata.name,
                        "status": pod.status.phase,
                        "ip": pod.status.pod_ip
                    })
                return agents
            except Exception as e:
                logger.error(f"Error listing agents: {e}")
                return []

        def deploy_worker(self, name: str, replicas: int = 1):
            """Scale the worker deployment."""
            if not self.apps_v1:
                return {"error": "Kubernetes not connected"}

            try:
                # In a real scenario, we might patch the specific deployment or create a new one
                # For now, we scale the generic 'agency-worker' deployment
                patch = {"spec": {"replicas": replicas}}
                self.apps_v1.patch_namespaced_deployment(
                    name="agency-worker",
                    namespace="agency",
                    body=patch
                )
                return {"status": "success", "message": f"Scaled worker to {replicas} replicas"}
            except Exception as e:
                return {"error": str(e)}

        def register_task(self, description: str, project_id: str) -> Dict[str, Any]:
            """Add a task to the Supabase queue."""
            if not self.supabase:
                return {"error": "Supabase not connected"}

            data = {
                "description": description,
                "project_id": project_id,
                "status": "pending"
            }
            try:
                response = self.supabase.table("tasks").insert(data).execute()
                return response.data
            except Exception as e:
                return {"error": str(e)}

    # --- MCP Server Setup ---

    mcp = FastMCP("Agency Manager")
    manager = AgencyManager()

    @mcp.tool()
    def get_agency_status() -> str:
        """Returns the current status of the agency (active agents, resource usage)."""
        agents = manager.list_active_agents()
        return f"Active Agents: {len(agents)}\nDetails: {agents}"

    @mcp.tool()
    def scale_workers(count: int) -> str:
        """Scales the number of generic worker nodes."""
        result = manager.deploy_worker("agency-worker", count)
        return str(result)

    @mcp.tool()
    def create_task(description: str, project_id: str) -> str:
        """Creates a new task in the backlog."""
        result = manager.register_task(description, project_id)
        return str(result)

    if __name__ == "__main__":
        # Start the MCP server
        mcp.run()
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: worker-code
  namespace: agency
data:
  node.py: |
    import os
    import json
    import time
    import logging
    import redis
    import subprocess
    from typing import Dict, Any

    # Configure logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] Worker: %(message)s')
    logger = logging.getLogger("AgencyWorker")

    class AgencyWorker:
        def __init__(self):
            # 1. Connect to Redis (Task Queue)
            self.redis_host = os.getenv("REDIS_HOST", "redis")
            self.redis_port = int(os.getenv("REDIS_PORT", 6379))
            self.queue_name = "agency:tasks"

            try:
                self.redis = redis.Redis(host=self.redis_host, port=self.redis_port, db=0, decode_responses=True)
                self.redis.ping()
                logger.info(f"Connected to Redis at {self.redis_host}:{self.redis_port}")
            except Exception as e:
                logger.error(f"Failed to connect to Redis: {e}")
                self.redis = None

            # 2. LiteLLM Configuration
            self.llm_base_url = os.getenv("LITELLM_URL", "http://litellm:4000")
            self.api_key = os.getenv("LITELLM_MASTER_KEY", "sk-agency-internal-key")

        def run_shell_command(self, command: str) -> str:
            """Executes a shell command safely."""
            logger.info(f"Executing command: {command}")
            try:
                result = subprocess.run(
                    command,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                return result.stdout if result.returncode == 0 else f"Error: {result.stderr}"
            except Exception as e:
                return f"Execution failed: {str(e)}"

        def process_task(self, task_json: str):
            """Parses and executes a task."""
            try:
                task = json.loads(task_json)
                task_type = task.get("type", "unknown")
                task_id = task.get("id", "unknown")

                logger.info(f"Processing task {task_id} of type {task_type}")

                result = ""
                if task_type == "shell":
                    result = self.run_shell_command(task.get("command", "echo 'No command'"))
                elif task_type == "echo":
                    result = f"Echo: {task.get("message")}"
                else:
                    result = f"Unknown task type: {task_type}"

                # In a real system, we would write this result back to Supabase or Redis
                logger.info(f"Task {task_id} complete. Result: {result[:50]}...")

            except json.JSONDecodeError:
                logger.error("Failed to decode task JSON")
            except Exception as e:
                logger.error(f"Error processing task: {e}")

        def start(self):
            """Main loop: Polls Redis for tasks."""
            if not self.redis:
                logger.error("Redis not connected. Exiting.")
                return

            logger.info("Worker started. Waiting for tasks...")
            while True:
                try:
                    # Blocking pop from the queue
                    # brpop returns a tuple (queue_name, data)
                    task_data = self.redis.brpop(self.queue_name, timeout=5)

                    if task_data:
                        self.process_task(task_data[1])

                    # Small sleep to prevent tight loop if redis goes down
                    time.sleep(0.1)

                except redis.ConnectionError:
                    logger.error("Redis connection lost. Retrying in 5s...")
                    time.sleep(5)
                except Exception as e:
                    logger.error(f"Unexpected error: {e}")
                    time.sleep(1)

    if __name__ == "__main__":
        worker = AgencyWorker()
        worker.start()
